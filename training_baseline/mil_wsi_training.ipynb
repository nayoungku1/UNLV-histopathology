{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIL 모델: WSI 하나 전체를 입력 (Bag 단위)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import defaultdict, Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mil_data_index(repo_id, label_csv_path):\n",
    "    df = pd.read_csv(label_csv_path)\n",
    "    filename_to_label = dict(zip(df['pub_subspec_id'], df['label']))\n",
    "    data_index = []\n",
    "    for fname, label in filename_to_label.items():\n",
    "        fname_with_ext = fname if fname.endswith(\".npz\") else f\"{fname}.npz\"\n",
    "        url = f\"https://huggingface.co/datasets/{repo_id}/resolve/main/{fname_with_ext}\"\n",
    "        data_index.append((url, label))\n",
    "    return data_index\n",
    "\n",
    "\n",
    "def stratified_split(data_index, train_ratio=0.7, val_ratio=0.15, seed=42):\n",
    "    label_to_items = defaultdict(list)\n",
    "    for item in data_index:\n",
    "        label = item[2]\n",
    "        label_to_items[label].append(item)\n",
    "\n",
    "    train, val, test = [], [], []\n",
    "    random.seed(seed)\n",
    "\n",
    "    for label, items in label_to_items.items():\n",
    "        random.shuffle(items)\n",
    "        n_total = len(items)\n",
    "        n_train = int(n_total * train_ratio)\n",
    "        n_val = int(n_total * 0.15)\n",
    "        train.extend(items[:n_train])\n",
    "        val.extend(items[n_train:n_train + n_val])\n",
    "        test.extend(items[n_train + n_val:])\n",
    "    return train, val, test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MILDataset(Dataset):\n",
    "    def __init__(self, data_index, transform=None):\n",
    "        self.data_index = data_index\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        url, label = self.data_index[idx]\n",
    "        response = requests.get(url)\n",
    "        npz = np.load(BytesIO(response.content))\n",
    "        patches = []\n",
    "        for key in npz.files:\n",
    "            patch = npz[key]\n",
    "            if patch.ndim == 2:\n",
    "                patch = Image.fromarray(patch.astype(np.uint8), mode='L')\n",
    "            elif patch.shape[-1] == 3:\n",
    "                patch = Image.fromarray(patch.astype(np.uint8), mode='RGB')\n",
    "            else:\n",
    "                patch = Image.fromarray(patch.astype(np.uint8))\n",
    "            if self.transform:\n",
    "                patch = self.transform(patch)\n",
    "            patches.append(patch)\n",
    "        patch_tensor = torch.stack(patches)  # Shape: (N, C, H, W)\n",
    "        return patch_tensor, int(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19814f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = \"nayoungku1/npz-histopathology-dataset\"\n",
    "label_csv_path = \"./metadata/label.csv\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "all_index = make_mil_data_index(repo_id, label_csv_path)\n",
    "train_idx, val_idx, test_idx = stratified_split(all_index)\n",
    "\n",
    "train_dataset = MILDataset(train_idx, transform=transform)\n",
    "val_dataset = MILDataset(val_idx, transform=transform)\n",
    "test_dataset = MILDataset(test_idx, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
