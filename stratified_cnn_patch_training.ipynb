{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ad36f887",
      "metadata": {
        "id": "ad36f887"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "from io import BytesIO\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cd62d291",
      "metadata": {
        "id": "cd62d291"
      },
      "outputs": [],
      "source": [
        "\n",
        "# CSV 파일 경로와 Huggingface repo_id\n",
        "label_csv_path = \"./label.csv\"  # CSV 파일 경로 수정 필요\n",
        "repo_id = \"nayoungku1/npz-histopathology-dataset\"     # Huggingface repo 경로 수정 필요\n",
        "\n",
        "df = pd.read_csv(label_csv_path)\n",
        "df['pub_subspec_id'] = df['pub_subspec_id'].apply(lambda x: x if x.endswith('.npz') else f\"{x}.npz\")\n",
        "\n",
        "# stratified 샘플링 (총 46개 샘플 선택)\n",
        "_, selected_df = train_test_split(\n",
        "    df,\n",
        "    test_size=46,\n",
        "    stratify=df['label'],\n",
        "    random_state=314\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b05c927e",
      "metadata": {
        "id": "b05c927e"
      },
      "outputs": [],
      "source": [
        "\n",
        "def make_stratified_data_index(repo_id, filtered_df):\n",
        "    filename_to_label = dict(zip(filtered_df['pub_subspec_id'], filtered_df['label']))\n",
        "    data_index = []\n",
        "\n",
        "    for fname, label in filename_to_label.items():\n",
        "        url = f\"https://huggingface.co/datasets/{repo_id}/resolve/main/{fname}\"\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            npz = np.load(BytesIO(response.content))\n",
        "            for key in npz.files:\n",
        "                patch_array = npz[key]\n",
        "                if patch_array.ndim == 4:\n",
        "                    for i in range(patch_array.shape[0]):\n",
        "                        data_index.append((url, key, i, label))\n",
        "                else:\n",
        "                    data_index.append((url, key, None, label))\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to load {fname}: {e}\")\n",
        "    return data_index\n",
        "\n",
        "data_index = make_stratified_data_index(repo_id, selected_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5552ed21",
      "metadata": {
        "id": "5552ed21"
      },
      "outputs": [],
      "source": [
        "\n",
        "def stratified_split(data_index, train_ratio=0.7, val_ratio=0.15, seed=314):\n",
        "    label_to_items = defaultdict(list)\n",
        "    for item in data_index:\n",
        "        label = item[3]\n",
        "        label_to_items[label].append(item)\n",
        "\n",
        "    train, val, test = [], [], []\n",
        "    random.seed(seed)\n",
        "\n",
        "    for label, items in label_to_items.items():\n",
        "        random.shuffle(items)\n",
        "        n_total = len(items)\n",
        "        n_train = int(n_total * train_ratio)\n",
        "        n_val = int(n_total * val_ratio)\n",
        "        train.extend(items[:n_train])\n",
        "        val.extend(items[n_train:n_train + n_val])\n",
        "        test.extend(items[n_train + n_val:])\n",
        "    return train, val, test\n",
        "\n",
        "train_index, val_index, test_index = stratified_split(data_index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a225a195",
      "metadata": {
        "id": "a225a195"
      },
      "outputs": [],
      "source": [
        "\n",
        "class PatchDataset(Dataset):\n",
        "    def __init__(self, data_index, transform=None):\n",
        "        self.data_index = data_index\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_index)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        url, key, patch_idx, label = self.data_index[idx]\n",
        "        response = requests.get(url)\n",
        "        npz = np.load(BytesIO(response.content))\n",
        "        patch_array = npz[key]\n",
        "\n",
        "        patch = patch_array[patch_idx] if patch_idx is not None else patch_array\n",
        "        patch = Image.fromarray(patch.astype(np.uint8))\n",
        "\n",
        "        if self.transform:\n",
        "            patch = self.transform(patch)\n",
        "\n",
        "        return patch, int(label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d8474dcf",
      "metadata": {
        "id": "d8474dcf"
      },
      "outputs": [],
      "source": [
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = PatchDataset(train_index, transform)\n",
        "val_dataset = PatchDataset(val_index, transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_loader:\n",
        "    print(images.shape, labels.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5O4cMvk4FPs",
        "outputId": "093293a0-682e-4d21-95da-5bf6980f6356"
      },
      "id": "i5O4cMvk4FPs",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 3, 256, 256]) torch.Size([128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataset))  # 학습용 patch 총 개수\n",
        "print(len(val_dataset))    # 검증용 patch 총 개수"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoK7aQ7B47RU",
        "outputId": "857c7585-5f83-4434-ef42-d1a675af31db"
      },
      "id": "qoK7aQ7B47RU",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13636\n",
            "2921\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "95bf4e5b",
      "metadata": {
        "id": "95bf4e5b"
      },
      "outputs": [],
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(64 * 64 * 64, 128)\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))  # [B, 32, 128, 128]\n",
        "        x = self.pool(torch.relu(self.conv2(x)))  # [B, 64, 64, 64]\n",
        "        x = x.view(-1, 64 * 64 * 64)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.sigmoid(self.fc2(x))\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTAOgz6-3V5o",
        "outputId": "af0173ca-a01c-423f-e5ba-099742326918"
      },
      "id": "TTAOgz6-3V5o",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNNModel().to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "25FYGhnD3Yxn"
      },
      "id": "25FYGhnD3Yxn",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e52ea62d",
      "metadata": {
        "id": "e52ea62d"
      },
      "outputs": [],
      "source": [
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.float().unsqueeze(1).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yCqfwFJS5AOX"
      },
      "id": "yCqfwFJS5AOX",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}