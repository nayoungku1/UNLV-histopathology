{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad36f887",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from io import BytesIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd62d291",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CSV 파일 경로와 Huggingface repo_id\n",
    "label_csv_path = \"./label.csv\"  # CSV 파일 경로 수정 필요\n",
    "repo_id = \"your-hf-repo-id\"     # Huggingface repo 경로 수정 필요\n",
    "\n",
    "df = pd.read_csv(label_csv_path)\n",
    "df['pub_subspec_id'] = df['pub_subspec_id'].apply(lambda x: x if x.endswith('.npz') else f\"{x}.npz\")\n",
    "\n",
    "# stratified 샘플링 (총 46개 샘플 선택)\n",
    "_, selected_df = train_test_split(\n",
    "    df,\n",
    "    test_size=46,\n",
    "    stratify=df['label'],\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05c927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_stratified_data_index(repo_id, filtered_df):\n",
    "    filename_to_label = dict(zip(filtered_df['pub_subspec_id'], filtered_df['label']))\n",
    "    data_index = []\n",
    "\n",
    "    for fname, label in filename_to_label.items():\n",
    "        url = f\"https://huggingface.co/datasets/{repo_id}/resolve/main/{fname}\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            npz = np.load(BytesIO(response.content))\n",
    "            for key in npz.files:\n",
    "                patch_array = npz[key]\n",
    "                if patch_array.ndim == 4:\n",
    "                    for i in range(patch_array.shape[0]):\n",
    "                        data_index.append((url, key, i, label))\n",
    "                else:\n",
    "                    data_index.append((url, key, None, label))\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to load {fname}: {e}\")\n",
    "    return data_index\n",
    "\n",
    "data_index = make_stratified_data_index(repo_id, selected_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5552ed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stratified_split(data_index, train_ratio=0.7, val_ratio=0.15, seed=42):\n",
    "    label_to_items = defaultdict(list)\n",
    "    for item in data_index:\n",
    "        label = item[3]\n",
    "        label_to_items[label].append(item)\n",
    "\n",
    "    train, val, test = [], [], []\n",
    "    random.seed(seed)\n",
    "\n",
    "    for label, items in label_to_items.items():\n",
    "        random.shuffle(items)\n",
    "        n_total = len(items)\n",
    "        n_train = int(n_total * train_ratio)\n",
    "        n_val = int(n_total * val_ratio)\n",
    "        train.extend(items[:n_train])\n",
    "        val.extend(items[n_train:n_train + n_val])\n",
    "        test.extend(items[n_train + n_val:])\n",
    "    return train, val, test\n",
    "\n",
    "train_index, val_index, test_index = stratified_split(data_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a225a195",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PatchDataset(Dataset):\n",
    "    def __init__(self, data_index, transform=None):\n",
    "        self.data_index = data_index\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        url, key, patch_idx, label = self.data_index[idx]\n",
    "        response = requests.get(url)\n",
    "        npz = np.load(BytesIO(response.content))\n",
    "        patch_array = npz[key]\n",
    "\n",
    "        patch = patch_array[patch_idx] if patch_idx is not None else patch_array\n",
    "        patch = Image.fromarray(patch.astype(np.uint8))\n",
    "\n",
    "        if self.transform:\n",
    "            patch = self.transform(patch)\n",
    "\n",
    "        return patch, int(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8474dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = PatchDataset(train_index, transform)\n",
    "val_dataset = PatchDataset(val_index, transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bf4e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 32 * 32, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 32 * 32)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52ea62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNModel().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
