{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6273b236",
   "metadata": {},
   "source": [
    "# CNN 모델: 패치 단위 학습용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbee3514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f796ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_index(repo_id, label_csv_path):\n",
    "    df = pd.read_csv(label_csv_path)\n",
    "    filename_to_label = dict(zip(df['pub_subspec_id'], df['label']))\n",
    "    data_index = []\n",
    "\n",
    "    for fname, label in filename_to_label.items():\n",
    "        fname_with_ext = fname if fname.endswith(\".npz\") else f\"{fname}.npz\"\n",
    "        url = f\"https://huggingface.co/datasets/{repo_id}/resolve/main/{fname_with_ext}\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            npz = np.load(BytesIO(response.content))\n",
    "            for key in npz.files:\n",
    "                patch_array = npz[key]\n",
    "                if patch_array.ndim == 4:\n",
    "                    for i in range(patch_array.shape[0]):\n",
    "                        data_index.append((url, key, i, label))\n",
    "                else:\n",
    "                    data_index.append((url, key, None, label))\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to load {fname_with_ext}: {e}\")\n",
    "    return data_index\n",
    "\n",
    "\n",
    "def stratified_split(data_index, train_ratio=0.7, val_ratio=0.15, seed=42):\n",
    "    label_to_items = defaultdict(list)\n",
    "    for item in data_index:\n",
    "        label = item[2]\n",
    "        label_to_items[label].append(item)\n",
    "\n",
    "    train, val, test = [], [], []\n",
    "    random.seed(seed)\n",
    "\n",
    "    for label, items in label_to_items.items():\n",
    "        random.shuffle(items)\n",
    "        n_total = len(items)\n",
    "        n_train = int(n_total * train_ratio)\n",
    "        n_val = int(n_total * 0.15)\n",
    "        train.extend(items[:n_train])\n",
    "        val.extend(items[n_train:n_train + n_val])\n",
    "        test.extend(items[n_train + n_val:])\n",
    "    return train, val, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee064641",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchDataset(Dataset):\n",
    "    def __init__(self, data_index, transform=None):\n",
    "        self.data_index = data_index\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        url, key, patch_idx, label = self.data_index[idx]\n",
    "        response = requests.get(url)\n",
    "        npz = np.load(BytesIO(response.content))\n",
    "        patch_array = npz[key]\n",
    "\n",
    "        if patch_idx is not None:\n",
    "            patch = patch_array[patch_idx]\n",
    "        else:\n",
    "            patch = patch_array  # 이미 3D이면 그대로\n",
    "\n",
    "        if patch.ndim == 2:\n",
    "            patch = Image.fromarray(patch.astype(np.uint8), mode='L')\n",
    "        elif patch.shape[-1] == 3:\n",
    "            patch = Image.fromarray(patch.astype(np.uint8), mode='RGB')\n",
    "        else:\n",
    "            patch = Image.fromarray(patch.astype(np.uint8))\n",
    "\n",
    "        if self.transform:\n",
    "            patch = self.transform(patch)\n",
    "\n",
    "        return patch, int(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "480cc079",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = \"nayoungku1/npz-histopathology-dataset\"\n",
    "label_csv_path = \"./metadata/label.csv\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "all_index = make_data_index(repo_id, label_csv_path)\n",
    "train_idx, val_idx, test_idx = stratified_split(all_index)\n",
    "\n",
    "train_dataset = PatchDataset(train_idx, transform=transform)\n",
    "val_dataset = PatchDataset(val_idx, transform=transform)\n",
    "test_dataset = PatchDataset(test_idx, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cdd68c3-5b25-4b95-9730-f16b0400dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 32 * 32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(self.conv(x))\n",
    "\n",
    "num_classes = len(pd.read_csv(label_csv_path)['label'].unique())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f18087-2dc1-4363-a0f5-cf320035b0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    total, correct, running_loss = 0, 0, 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, preds = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "    print(f\"Epoch {epoch+1} | Train Acc: {correct/total:.2%}, Loss: {running_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b23da0-2329-400d-a030-a85bd441495f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
