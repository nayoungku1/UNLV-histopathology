{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# CNN \ubaa8\ub378: \ud328\uce58 \ub2e8\uc704 \ud559\uc2b5\uc6a9"}, {"cell_type": "code", "metadata": {}, "source": "import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nimport requests\nfrom io import BytesIO\nimport pandas as pd\nimport torchvision\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom torchvision import transforms\nimport torch.nn as nn\nimport torch.optim as optim\nimport random\nfrom collections import defaultdict, Counter\n"}, {"cell_type": "code", "metadata": {}, "source": "def make_data_index(repo_id, label_csv_path):\n    df = pd.read_csv(label_csv_path)\n    filename_to_label = dict(zip(df['filename'], df['label']))\n    data_index = []\n\n    for fname, label in filename_to_label.items():\n        fname_with_ext = fname if fname.endswith(\".npz\") else f\"{fname}.npz\"\n        url = f\"https://huggingface.co/datasets/{repo_id}/resolve/main/{fname_with_ext}\"\n        try:\n            response = requests.get(url)\n            npz = np.load(BytesIO(response.content))\n            for key in npz.files:\n                data_index.append((url, key, label))\n        except Exception as e:\n            print(f\"\u274c Failed to load {fname_with_ext}: {e}\")\n    return data_index\n\ndef stratified_split(data_index, train_ratio=0.7, val_ratio=0.15, seed=42):\n    label_to_items = defaultdict(list)\n    for item in data_index:\n        label = item[2]\n        label_to_items[label].append(item)\n\n    train, val, test = [], [], []\n    random.seed(seed)\n\n    for label, items in label_to_items.items():\n        random.shuffle(items)\n        n_total = len(items)\n        n_train = int(n_total * train_ratio)\n        n_val = int(n_total * 0.15)\n        train.extend(items[:n_train])\n        val.extend(items[n_train:n_train + n_val])\n        test.extend(items[n_train + n_val:])\n    return train, val, test\n"}, {"cell_type": "code", "metadata": {}, "source": "class PatchDataset(Dataset):\n    def __init__(self, data_index, transform=None):\n        self.data_index = data_index\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data_index)\n\n    def __getitem__(self, idx):\n        url, key, label = self.data_index[idx]\n        response = requests.get(url)\n        npz = np.load(BytesIO(response.content))\n        patch = npz[key]\n        if patch.ndim == 2:\n            patch = Image.fromarray(patch.astype(np.uint8), mode='L')\n        elif patch.shape[-1] == 3:\n            patch = Image.fromarray(patch.astype(np.uint8), mode='RGB')\n        else:\n            patch = Image.fromarray(patch.astype(np.uint8))\n        if self.transform:\n            patch = self.transform(patch)\n        return patch, int(label)\n"}, {"cell_type": "code", "metadata": {}, "source": "repo_id = \"\ubdf0\ud2f0\uace0/my-patch-dataset\"\nlabel_csv_path = \"./label.csv\"\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor()\n])\n\nall_index = make_data_index(repo_id, label_csv_path)\ntrain_idx, val_idx, test_idx = stratified_split(all_index)\n\ntrain_dataset = PatchDataset(train_idx, transform=transform)\nval_dataset = PatchDataset(val_idx, transform=transform)\ntest_dataset = PatchDataset(test_idx, transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 5}